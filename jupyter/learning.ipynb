{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"aomJUY_gvXed"},"source":["Initialise code for google colab\n","\n","Mount google drive"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19142,"status":"ok","timestamp":1675005956808,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"GAjcLhjCgpxv","outputId":"87bf36dd-2f11-40c7-ec58-a5a12db6fb88"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2558,"status":"ok","timestamp":1675005935258,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"A4muRHlqelbj","outputId":"164b6f74-de75-42c0-e946-279e82e32183"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.11.0\n","0.19.0\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","import tensorflow_addons as tfa\n","print(tfa.__version__)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61908,"status":"ok","timestamp":1675005913429,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"dV7s-SFUelbk","outputId":"70f59214-9c55-4384-be67-7385f0c5e640"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.11\n","  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (21.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (1.15.0)\n","Collecting tensorboard<2.12,>=2.11\n","  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (1.3.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (1.51.1)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (4.4.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (2.2.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (0.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (1.14.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (15.0.6.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (1.6.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (3.3.0)\n","Collecting tensorflow-estimator<2.12,>=2.11.0\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.12,>=2.11.0\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (0.29.0)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (3.1.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (3.19.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11) (57.4.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.11) (0.38.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.16.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.25.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (0.4.6)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow==2.11) (3.0.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (5.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11) (6.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (4.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.2.2)\n","Installing collected packages: flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.9.0\n","    Uninstalling tensorflow-estimator-2.9.0:\n","      Successfully uninstalled tensorflow-estimator-2.9.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.9.0\n","    Uninstalling keras-2.9.0:\n","      Successfully uninstalled keras-2.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.1\n","    Uninstalling tensorboard-2.9.1:\n","      Successfully uninstalled tensorboard-2.9.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.2\n","    Uninstalling tensorflow-2.9.2:\n","      Successfully uninstalled tensorflow-2.9.2\n","Successfully installed flatbuffers-23.1.21 keras-2.11.0 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-addons==0.19\n","  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons==0.19) (21.3)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons==0.19) (2.7.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons==0.19) (3.0.9)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.19.0\n"]}],"source":["!pip install tensorflow==2.11\n","!pip install tensorflow-addons==0.19"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"J3iW3Uff2Jyh"},"source":["Create data base files under google colab environment"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":26350,"status":"ok","timestamp":1675005995952,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"D1ubGnuD2CXZ"},"outputs":[],"source":["!unzip -q '/content/drive/MyDrive/data_equalize.zip' -d '/content/'"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nnQuhv17x7hK"},"source":["Define working directory to our jupyter repertory:\n","* because path to the different repertories (./data, ./output...) are define relatevly to jupyter one\n","* let import _mypath which add ./lib to python path in order to import our own define libraries\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1225,"status":"ok","timestamp":1675006058913,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"B2HJyd5welbm","outputId":"2c3aac34-7d36-4c6b-a8a5-781a89547d91"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/covid-19-xRay/jupyter\n"]}],"source":["# for google colab use\n","%cd /content/drive/MyDrive/DS_MLOPS/jupyter\n","from google.colab.patches import cv2_imshow\n","db_work_dir = '/content'\n","work_dir = '..'"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"10je8Bxoelbn"},"outputs":[],"source":["# for local use\n","db_work_dir = '../input/db/'\n","work_dir = '..'"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1683,"status":"ok","timestamp":1675006063896,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"6c135d84"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-21 17:56:39.775506: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import _mypath\n","import os\n","import shutil\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import cv2\n","from PIL import Image\n","import joblib\n","\n","%load_ext autoreload\n","%autoreload 1"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3548,"status":"ok","timestamp":1675006069297,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"YP-ouMbVelbn"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/luc/.local/share/virtualenvs/DS_MLOps-0EOZ04fs/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n"]}],"source":["%aimport database.path_origin_data\n","%aimport database.dataset\n","\n","from database.path_origin_data import build_data_paths \n","from database.path_origin_data import lung_name, infection_name\n","from database.path_origin_data import train_name, test_name, valid_name\n","from database.path_origin_data import normal_name, covid_name, no_covid_name\n","from database.path_origin_data import images_name, lung_mask_name, infection_mask_name\n","\n","from database.dataset import build_dataset\n","\n","%aimport run_exp.test\n","%aimport run_exp.standard\n","\n","from run_exp.test import compile_test_model, test_accuracy, test_conf_mat\n","from run_exp.standard import run_experiment as run_experiment_pure_cnn\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"76855cab"},"source":["Build paths and variables for reading data base hierarchy"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"XZhnTtABelbo"},"outputs":[],"source":["# db\n","db_name = 'data_add'\n","db_path = os.path.join(db_work_dir, db_name)\n","\n","# input\n","input_path = os.path.join(work_dir, 'input')\n","\n","data_name = 'data'\n","data_path = os.path.join(input_path, data_name)\n","\n","model_name = 'model'\n","model_path = os.path.join(input_path, model_name)\n","\n","# output\n","output_path = os.path.join('..', 'output', 'learning')\n","if not os.path.exists(output_path):\n","    os.makedirs(output_path, exist_ok=True)\n","\n","log_path = os.path.join(output_path, 'log')\n","if not os.path.exists(log_path):\n","    os.makedirs(log_path, exist_ok=True)\n","\n","ckpt_path = os.path.join(output_path, 'ckpt')\n","if not os.path.exists(ckpt_path):\n","    os.makedirs(ckpt_path, exist_ok=True)\n","\n","metric_path = os.path.join(output_path, 'metric')\n","if not os.path.exists(metric_path):\n","    os.makedirs(metric_path, exist_ok=True)\n","\n","grad_cam_path = os.path.join(output_path, 'grad_cam')\n","if not os.path.exists(grad_cam_path):\n","    os.makedirs(grad_cam_path, exist_ok=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fec096c7"},"source":["Structure to manage paths in data base"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":218,"status":"ok","timestamp":1675006081199,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"a1271f47"},"outputs":[],"source":["data_paths = build_data_paths()\n","idx = pd.IndexSlice"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IXCOdbU7elbp"},"source":["Create tf Dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3735,"status":"ok","timestamp":1675006087575,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"FcSf_2y4elbp","outputId":"262975f4-0052-435e-93a1-8b4e5ec531c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1324 files belonging to 1 classes.\n","Found 1438 files belonging to 1 classes.\n","Found 1452 files belonging to 1 classes.\n","Found 400 files belonging to 1 classes.\n","Found 445 files belonging to 1 classes.\n","Found 450 files belonging to 1 classes.\n","Found 321 files belonging to 1 classes.\n","Found 364 files belonging to 1 classes.\n","Found 363 files belonging to 1 classes.\n","4214\n","4214\n"]}],"source":["\n","paths = data_paths['path']\n","\n","ds_train, ds_train_file_paths = build_dataset(db_path, paths, db=[lung_name], ds=[train_name])\n","ds_test, ds_test_file_paths = build_dataset(db_path, paths, db=[lung_name], ds=[test_name])\n","ds_valid, ds_valid_file_paths = build_dataset(db_path, paths, db=[lung_name], ds=[valid_name])\n","print(ds_train.cardinality().numpy())\n","print(len(ds_train_file_paths))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oULvMsKSelbp"},"source":["Model parameters"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":264,"status":"ok","timestamp":1675006094735,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"St2GGM-zelbp"},"outputs":[],"source":["batch_size_cnn = 32\n","batch_size_transformer = 32\n","\n","image_size = 256\n","input_shape = (image_size, image_size, 1)\n","\n","learning_rate = 0.001\n","weight_decay = 0.0001\n","num_epochs = 100\n","\n","label_smoothing = 0.1\n","lam_recon = 10.\n","patience = 5\n","min_delta = 0.005\n","min_delta_fine_tuning = 0.0005\n","\n","# data augmentation\n","scale = 1. / 255.\n","flip = \"horizontal\"\n","rotation_factor = 10. / 360.\n","zoom_height_factor = 0.2\n","zoom_width_factor = 0.2\n","\n","# vit\n","patch_size = 1\n","transformer_layers = 4\n","num_heads = 8\n","projection_dim = 64\n","transformer_units_rate = [2, 1]\n","mlp_head_units = [1024, 256]  # Size of the dense layers of the final classifier\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HpGXjB_lelbq"},"source":["Data augmentation"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":245,"status":"ok","timestamp":1675006099424,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"HMe_zlMGelbq"},"outputs":[],"source":["augmentation = keras.Sequential(\n","    [\n","      layers.Rescaling(scale=scale),\n","      layers.RandomFlip(flip),\n","      layers.RandomRotation(rotation_factor),\n","      layers.RandomZoom(height_factor=zoom_height_factor, width_factor=zoom_width_factor),\n","    ],\n","    name='augmentation'\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"tQeJmFhXelbq"},"source":["cnn encoder"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":236,"status":"ok","timestamp":1675006102452,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"LOHNNFhrelbq"},"outputs":[],"source":["from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dropout\n","\n","encoder = keras.Sequential(\n","    [\n","      layers.Conv2D(128, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n","      layers.MaxPooling2D(pool_size = (2, 2)),\n","      layers.Conv2D(128, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n","      layers.MaxPooling2D(pool_size = (2, 2)),\n","      layers.Conv2D(64, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n","      layers.MaxPooling2D(pool_size = (2, 2)),\n","      layers.Conv2D(64, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n","      layers.MaxPooling2D(pool_size = (2, 2)),\n","      layers.Conv2D(64, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n","      layers.MaxPooling2D(pool_size = (2, 2)),\n","      layers.Flatten(),\n","    ],\n","    name='encoder'\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"aVIjXbtcelbr"},"outputs":[],"source":["classifier = keras.Sequential(\n","    [\n","      layers.Dense(1024, activation='relu'),\n","      layers.Dense(256, activation='relu'),\n","      layers.Dense(3, activation='softmax'),\n","    ],\n","    name='classifier'\n",")\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":248,"status":"ok","timestamp":1675006146168,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"kX_B3Q95elbs"},"outputs":[],"source":["# Sub Model\n","shared_encoder = keras.Sequential(name='shared_encoder')\n","\n","for layer in encoder.layers[:-1]:\n","  shared_encoder.add(layer)\n","\n","# for layer in shared_encoder.layers:\n","#   layer.trainable = False\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5227,"status":"ok","timestamp":1675006155700,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"0qKrJS3yelbt","outputId":"25a09d91-707f-475d-c611-b1e49d9822ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," augmentation (Sequential)      (None, 256, 256, 1)  0           ['input_1[0][0]']                \n","                                                                                                  \n"," shared_encoder (Sequential)    (None, 8, 8, 64)     296512      ['augmentation[0][0]']           \n","                                                                                                  \n"," patches (Patches)              (None, None, 64)     0           ['shared_encoder[0][0]']         \n","                                                                                                  \n"," patch_encoder (PatchEncoder)   (None, 64, 64)       8256        ['patches[0][0]']                \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 64, 64)      128         ['patch_encoder[0][0]']          \n"," alization)                                                                                       \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 64, 64)      132672      ['layer_normalization[0][0]',    \n"," dAttention)                                                      'layer_normalization[0][0]']    \n","                                                                                                  \n"," add (Add)                      (None, 64, 64)       0           ['multi_head_attention[0][0]',   \n","                                                                  'patch_encoder[0][0]']          \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 64, 64)      128         ['add[0][0]']                    \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_4 (Dense)                (None, 64, 128)      8320        ['layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout (Dropout)              (None, 64, 128)      0           ['dense_4[0][0]']                \n","                                                                                                  \n"," dense_5 (Dense)                (None, 64, 64)       8256        ['dropout[0][0]']                \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 64, 64)       0           ['dense_5[0][0]']                \n","                                                                                                  \n"," add_1 (Add)                    (None, 64, 64)       0           ['dropout_1[0][0]',              \n","                                                                  'add[0][0]']                    \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 64, 64)      128         ['add_1[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 64, 64)      132672      ['layer_normalization_2[0][0]',  \n"," eadAttention)                                                    'layer_normalization_2[0][0]']  \n","                                                                                                  \n"," add_2 (Add)                    (None, 64, 64)       0           ['multi_head_attention_1[0][0]', \n","                                                                  'add_1[0][0]']                  \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 64, 64)      128         ['add_2[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_6 (Dense)                (None, 64, 128)      8320        ['layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 64, 128)      0           ['dense_6[0][0]']                \n","                                                                                                  \n"," dense_7 (Dense)                (None, 64, 64)       8256        ['dropout_2[0][0]']              \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 64, 64)       0           ['dense_7[0][0]']                \n","                                                                                                  \n"," add_3 (Add)                    (None, 64, 64)       0           ['dropout_3[0][0]',              \n","                                                                  'add_2[0][0]']                  \n","                                                                                                  \n"," layer_normalization_4 (LayerNo  (None, 64, 64)      128         ['add_3[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_2 (MultiH  (None, 64, 64)      132672      ['layer_normalization_4[0][0]',  \n"," eadAttention)                                                    'layer_normalization_4[0][0]']  \n","                                                                                                  \n"," add_4 (Add)                    (None, 64, 64)       0           ['multi_head_attention_2[0][0]', \n","                                                                  'add_3[0][0]']                  \n","                                                                                                  \n"," layer_normalization_5 (LayerNo  (None, 64, 64)      128         ['add_4[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_8 (Dense)                (None, 64, 128)      8320        ['layer_normalization_5[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 64, 128)      0           ['dense_8[0][0]']                \n","                                                                                                  \n"," dense_9 (Dense)                (None, 64, 64)       8256        ['dropout_4[0][0]']              \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 64, 64)       0           ['dense_9[0][0]']                \n","                                                                                                  \n"," add_5 (Add)                    (None, 64, 64)       0           ['dropout_5[0][0]',              \n","                                                                  'add_4[0][0]']                  \n","                                                                                                  \n"," layer_normalization_6 (LayerNo  (None, 64, 64)      128         ['add_5[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_3 (MultiH  (None, 64, 64)      132672      ['layer_normalization_6[0][0]',  \n"," eadAttention)                                                    'layer_normalization_6[0][0]']  \n","                                                                                                  \n"," add_6 (Add)                    (None, 64, 64)       0           ['multi_head_attention_3[0][0]', \n","                                                                  'add_5[0][0]']                  \n","                                                                                                  \n"," layer_normalization_7 (LayerNo  (None, 64, 64)      128         ['add_6[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_10 (Dense)               (None, 64, 128)      8320        ['layer_normalization_7[0][0]']  \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 64, 128)      0           ['dense_10[0][0]']               \n","                                                                                                  \n"," dense_11 (Dense)               (None, 64, 64)       8256        ['dropout_6[0][0]']              \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 64, 64)       0           ['dense_11[0][0]']               \n","                                                                                                  \n"," add_7 (Add)                    (None, 64, 64)       0           ['dropout_7[0][0]',              \n","                                                                  'add_6[0][0]']                  \n","                                                                                                  \n"," layer_normalization_8 (LayerNo  (None, 64, 64)      128         ['add_7[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 4096)         0           ['layer_normalization_8[0][0]']  \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, 4096)         0           ['flatten_1[0][0]']              \n","                                                                                                  \n"," dense_12 (Dense)               (None, 1024)         4195328     ['dropout_8[0][0]']              \n","                                                                                                  \n"," dropout_9 (Dropout)            (None, 1024)         0           ['dense_12[0][0]']               \n","                                                                                                  \n"," dense_13 (Dense)               (None, 256)          262400      ['dropout_9[0][0]']              \n","                                                                                                  \n"," dropout_10 (Dropout)           (None, 256)          0           ['dense_13[0][0]']               \n","                                                                                                  \n"," dense_14 (Dense)               (None, 3)            771         ['dropout_10[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 5,361,411\n","Trainable params: 5,361,411\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["\n","%aimport myLayers.vision_transformer\n","%aimport myLayers.mlp\n","from myLayers.vision_transformer import add_vit\n","\n","inputs = layers.Input(shape=input_shape)\n","augmented_transformer = augmentation(inputs)\n","shared_encoded = shared_encoder(augmented_transformer)\n","features = add_vit(shared_encoded,\n","            patch_size=patch_size,\n","            input_image_size=shared_encoded.shape[1],\n","            transformer_layers=transformer_layers,\n","            num_heads=num_heads,\n","            projection_dim=projection_dim,\n","            transformer_units_rate=transformer_units_rate,\n","            mlp_head_units=mlp_head_units)\n","# Classify outputs.\n","softmax = layers.Dense(3, activation='softmax', kernel_initializer='random_normal')(features)\n","\n","# Create the Keras model\n","model = keras.Model(inputs=inputs, outputs=softmax)\n","# shared_encoder.summary()\n","model.summary()\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["model_name = 'mlops_cnn_vit_model_weights.hdf5'\n","model_full_path = os.path.join(model_path, model_name)\n","model.load_weights(model_full_path)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1981246,"status":"ok","timestamp":1674815639626,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"UdbqZ5jGelbt","outputId":"0585e73a-6425-4122-ec85-6d14ac8a30cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["2023-05-21 17:59:06.416762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1324]\n","\t [[{{node Placeholder/_0}}]]\n","2023-05-21 17:59:06.417963: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_25' with dtype string and shape [1452]\n","\t [[{{node Placeholder/_25}}]]\n"]},{"name":"stdout","output_type":"stream","text":[" 16/132 [==>...........................] - ETA: 15:53 - loss: 0.6237 - accuracy: 0.8320"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrun_exp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstandard\u001b[39;00m \u001b[39mimport\u001b[39;00m run_experiment \u001b[39mas\u001b[39;00m run_experiment_transformer\n\u001b[1;32m      4\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnew_model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m transformer_history \u001b[39m=\u001b[39m run_experiment_transformer(\n\u001b[1;32m      6\u001b[0m     model,\n\u001b[1;32m      7\u001b[0m     ds_train, ds_valid, ds_test,\n\u001b[1;32m      8\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size_transformer, num_epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m      9\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mlearning_rate \u001b[39m/\u001b[39;49m \u001b[39m2.\u001b[39;49m, weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m     10\u001b[0m     from_logits\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, label_smoothing\u001b[39m=\u001b[39;49mlabel_smoothing,\n\u001b[1;32m     11\u001b[0m     patience\u001b[39m=\u001b[39;49mpatience, min_delta\u001b[39m=\u001b[39;49mmin_delta,\n\u001b[1;32m     12\u001b[0m     log_path\u001b[39m=\u001b[39;49mlog_path, ckpt_path\u001b[39m=\u001b[39;49mckpt_path,\n\u001b[1;32m     13\u001b[0m     prefix\u001b[39m=\u001b[39;49mmodel_name\n\u001b[1;32m     14\u001b[0m )\n","File \u001b[0;32m~/git/DS_MLOps/jupyter/../lib/run_exp/standard.py:64\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model, ds_train, ds_valid, ds_test, batch_size, num_epochs, learning_rate, weight_decay, from_logits, label_smoothing, patience, min_delta, log_path, ckpt_path, prefix)\u001b[0m\n\u001b[1;32m     62\u001b[0m card \u001b[39m=\u001b[39m ds_train\u001b[39m.\u001b[39mcardinality()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     63\u001b[0m ds_shuffle \u001b[39m=\u001b[39m ds_train\u001b[39m.\u001b[39mshuffle(card, reshuffle_each_iteration\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 64\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     65\u001b[0m     x\u001b[39m=\u001b[39;49mds_shuffle\u001b[39m.\u001b[39;49mbatch(batch_size),\n\u001b[1;32m     66\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     67\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[1;32m     68\u001b[0m     validation_data\u001b[39m=\u001b[39;49mds_valid\u001b[39m.\u001b[39;49mbatch(batch_size),\n\u001b[1;32m     69\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     70\u001b[0m         log,\n\u001b[1;32m     71\u001b[0m         checkpoint_callback,\n\u001b[1;32m     72\u001b[0m         custom_early_stopping,\n\u001b[1;32m     73\u001b[0m         \u001b[39m# custom_reduce_lr_on_plateau,\u001b[39;49;00m\n\u001b[1;32m     74\u001b[0m     ],\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     77\u001b[0m \u001b[39mreturn\u001b[39;00m history\n","File \u001b[0;32m~/.local/share/virtualenvs/DS_MLOps-0EOZ04fs/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/share/virtualenvs/DS_MLOps-0EOZ04fs/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/.local/share/virtualenvs/DS_MLOps-0EOZ04fs/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.local/share/virtualenvs/DS_MLOps-0EOZ04fs/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/.local/share/virtualenvs/DS_MLOps-0EOZ04fs/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/.local/share/virtualenvs/DS_MLOps-0EOZ04fs/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/.local/share/virtualenvs/DS_MLOps-0EOZ04fs/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/.local/share/virtualenvs/DS_MLOps-0EOZ04fs/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/.local/share/virtualenvs/DS_MLOps-0EOZ04fs/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%aimport run_exp.standard\n","from run_exp.standard import run_experiment as run_experiment_transformer\n","\n","model_name = 'new_model'\n","transformer_history = run_experiment_transformer(\n","    model,\n","    ds_train, ds_valid, ds_test,\n","    batch_size=batch_size_transformer, num_epochs=num_epochs,\n","    learning_rate=learning_rate / 2., weight_decay=weight_decay,\n","    from_logits=False, label_smoothing=label_smoothing,\n","    patience=patience, min_delta=min_delta,\n","    log_path=log_path, ckpt_path=ckpt_path,\n","    prefix=model_name\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crV7qWT834Vd"},"outputs":[],"source":["# model_name = 'new_model'\n","checkpoint_filename = os.path.join(ckpt_path, model_name + '_weights.hdf5')\n","model.load_weights(checkpoint_filename)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"elapsed":66685,"status":"ok","timestamp":1674823216321,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-60},"id":"R1boKCYXEJQs","outputId":"09fe74b0-4f58-45aa-db20-de46d5aaf0a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["213/213 [==============================] - 26s 72ms/step - loss: 0.4304 - accuracy: 0.9262\n","Test accuracy: 92.62%\n","213/213 [==============================] - 14s 59ms/step\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"]},{"data":{"text/html":["\n","  <div id=\"df-10b39b90-d3a0-431a-9529-a739e9ec4845\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>Predicted</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","    <tr>\n","      <th>Real</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2030</td>\n","      <td>13</td>\n","      <td>97</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>69</td>\n","      <td>2234</td>\n","      <td>91</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>213</td>\n","      <td>18</td>\n","      <td>2022</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10b39b90-d3a0-431a-9529-a739e9ec4845')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-10b39b90-d3a0-431a-9529-a739e9ec4845 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-10b39b90-d3a0-431a-9529-a739e9ec4845');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["Predicted     0     1     2\n","Real                       \n","0          2030    13    97\n","1            69  2234    91\n","2           213    18  2022"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["y_test_pd, y_pred_pd, accuracy, conf_mat, report = compile_test_model(\n","    model,\n","    ds_test, batch_size_transformer,\n","    from_logits=False, label_smoothing=label_smoothing\n",")\n","\n","print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","\n","print(report)\n","f_name = os.path.join(metric_path, model_name + '_report.txt')\n","with open(f_name, \"w\") as text_file:\n","  text_file.write(report)\n","\n","conf_mat\n","f_name = os.path.join(metric_path, model_name + '_conf_mat.joblib')\n","joblib.dump(conf_mat, f_name)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"covid-19-xRay-gI8RPtYc","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ec449b28ee1275c8ed3472cdab9bc054b62d41bc2731e9c066fdcbfc125fb022"}}},"nbformat":4,"nbformat_minor":0}
