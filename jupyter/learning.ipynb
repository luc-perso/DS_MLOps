{"cells":[{"cell_type":"markdown","metadata":{"id":"aomJUY_gvXed"},"source":["Initialise code for google colab\n","\n","Mount google drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28816,"status":"ok","timestamp":1684687532834,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"GAjcLhjCgpxv","outputId":"fc6a3064-f440-4b44-edcf-94380b828f44"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5108,"status":"ok","timestamp":1684687689599,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"A4muRHlqelbj","outputId":"e16330e4-5e1a-4af2-83b4-a9a09c87e717"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.11.0\n","0.19.0\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","import tensorflow_addons as tfa\n","print(tfa.__version__)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":66753,"status":"ok","timestamp":1684687611391,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"dV7s-SFUelbk","outputId":"56e1f265-34ae-490f-f219-0d13614f2f6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.11\n","  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (3.8.0)\n","Collecting keras<2.12,>=2.11.0 (from tensorflow==2.11)\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (16.0.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.22.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (23.1)\n","Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.11)\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.16.0)\n","Collecting tensorboard<2.12,>=2.11 (from tensorflow==2.11)\n","  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11)\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11) (0.40.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.17.3)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.27.1)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.2.2)\n","Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.0\n","    Uninstalling tensorboard-data-server-0.7.0:\n","      Successfully uninstalled tensorboard-data-server-0.7.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.2\n","    Uninstalling tensorboard-2.12.2:\n","      Successfully uninstalled tensorboard-2.12.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google","keras","tensorboard","tensorflow"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-addons==0.19\n","  Downloading tensorflow_addons-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.19) (23.1)\n","Collecting typeguard>=2.7 (from tensorflow-addons==0.19)\n","  Downloading typeguard-4.0.0-py3-none-any.whl (33 kB)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.19) (4.5.0)\n","Installing collected packages: typeguard, tensorflow-addons\n","Successfully installed tensorflow-addons-0.19.0 typeguard-4.0.0\n"]}],"source":["!pip install tensorflow==2.11\n","!pip install tensorflow-addons==0.19"]},{"cell_type":"markdown","metadata":{"id":"J3iW3Uff2Jyh"},"source":["Create data base files under google colab environment"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"2xKcHA9QMtWy","executionInfo":{"status":"ok","timestamp":1684687701570,"user_tz":-120,"elapsed":418,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"}}},"outputs":[],"source":["!mkdir '/content/db'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":28011,"status":"ok","timestamp":1684687756744,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"D1ubGnuD2CXZ"},"outputs":[],"source":["!unzip -q '/content/drive/MyDrive/data_origin.zip' -d '/content/db/'"]},{"cell_type":"code","source":["!unzip -q '/content/drive/MyDrive/data_add.zip' -d '/content/db/'"],"metadata":{"id":"ugwZMODLcYRp","executionInfo":{"status":"ok","timestamp":1684691603838,"user_tz":-120,"elapsed":9189,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["!rm -rf /content/db/__MACOSX"],"metadata":{"id":"FE-A-wNLPIUq","executionInfo":{"status":"ok","timestamp":1684691610316,"user_tz":-120,"elapsed":488,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nnQuhv17x7hK"},"source":["Define working directory to our jupyter repertory:\n","* because path to the different repertories (./data, ./output...) are define relatevly to jupyter one\n","* let import _mypath which add ./lib to python path in order to import our own define libraries\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684687846294,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"B2HJyd5welbm","outputId":"6c48dc67-890e-4908-ae3d-e9f690ec952a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DS_MLOps/jupyter\n"]}],"source":["# for google colab use\n","%cd /content/drive/MyDrive/DS_MLOps/jupyter\n","from google.colab.patches import cv2_imshow\n","db_path = '/content/db'\n","work_dir = '..'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"10je8Bxoelbn"},"outputs":[],"source":["# for local use\n","db_path = '../input/db/'\n","work_dir = '..'"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2165,"status":"ok","timestamp":1684687852490,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"6c135d84"},"outputs":[],"source":["import _mypath\n","import os\n","import shutil\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import cv2\n","from PIL import Image\n","import joblib\n","\n","%load_ext autoreload\n","%autoreload 1"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5968,"status":"ok","timestamp":1684687863409,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"YP-ouMbVelbn"},"outputs":[],"source":["%aimport database.path_origin_data\n","%aimport database.dataset\n","\n","from database.path_origin_data import build_data_paths \n","from database.path_origin_data import lung_name, infection_name\n","from database.path_origin_data import train_name, test_name, valid_name\n","from database.path_origin_data import normal_name, covid_name, no_covid_name\n","from database.path_origin_data import images_name, lung_mask_name, infection_mask_name\n","\n","from database.dataset import build_dataset\n","\n","%aimport run_exp.test\n","%aimport run_exp.standard\n","\n","from run_exp.test import compile_test_model, test_accuracy, test_conf_mat\n","from run_exp.standard import run_experiment as run_experiment_pure_cnn\n"]},{"cell_type":"markdown","metadata":{"id":"76855cab"},"source":["Build paths and variables for reading data base hierarchy"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XZhnTtABelbo","executionInfo":{"status":"ok","timestamp":1684687866016,"user_tz":-120,"elapsed":424,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"}}},"outputs":[],"source":["# input\n","input_path = os.path.join(work_dir, 'input')\n","\n","data_name = 'data'\n","data_path = os.path.join(input_path, data_name)\n","\n","model_name = 'model'\n","model_path = os.path.join(input_path, model_name)\n","\n","# output\n","output_path = os.path.join('..', 'output', 'learning')\n","if not os.path.exists(output_path):\n","    os.makedirs(output_path, exist_ok=True)\n","\n","log_path = os.path.join(output_path, 'log')\n","if not os.path.exists(log_path):\n","    os.makedirs(log_path, exist_ok=True)\n","\n","ckpt_path = os.path.join(output_path, 'ckpt')\n","if not os.path.exists(ckpt_path):\n","    os.makedirs(ckpt_path, exist_ok=True)\n","\n","metric_path = os.path.join(output_path, 'metric')\n","if not os.path.exists(metric_path):\n","    os.makedirs(metric_path, exist_ok=True)\n","\n","grad_cam_path = os.path.join(output_path, 'grad_cam')\n","if not os.path.exists(grad_cam_path):\n","    os.makedirs(grad_cam_path, exist_ok=True)\n"]},{"cell_type":"markdown","metadata":{"id":"fec096c7"},"source":["Structure to manage paths in data base"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":626,"status":"ok","timestamp":1684687873178,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"a1271f47"},"outputs":[],"source":["data_paths = build_data_paths()\n","idx = pd.IndexSlice"]},{"cell_type":"markdown","metadata":{"id":"IXCOdbU7elbp"},"source":["Create tf Dataset"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1566,"status":"ok","timestamp":1684691629765,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"FcSf_2y4elbp","outputId":"887b5a79-7f55-4380-ee3c-0f8521f646bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1324 files belonging to 1 classes.\n","Found 1438 files belonging to 1 classes.\n","Found 1452 files belonging to 1 classes.\n","Found 400 files belonging to 1 classes.\n","Found 445 files belonging to 1 classes.\n","Found 450 files belonging to 1 classes.\n","Found 321 files belonging to 1 classes.\n","Found 364 files belonging to 1 classes.\n","Found 363 files belonging to 1 classes.\n","Found 5525 files belonging to 1 classes.\n","Found 6220 files belonging to 1 classes.\n","Found 5756 files belonging to 1 classes.\n","Found 1740 files belonging to 1 classes.\n","Found 1949 files belonging to 1 classes.\n","Found 1803 files belonging to 1 classes.\n","Found 1391 files belonging to 1 classes.\n","Found 1538 files belonging to 1 classes.\n","Found 1439 files belonging to 1 classes.\n","21715\n"]}],"source":["\n","paths = data_paths['path']\n","\n","dir_paths = os.listdir(db_path)\n","\n","ds_train = None\n","ds_test = None\n","ds_valid = None\n","for path in dir_paths:\n","    full_path = os.path.join(db_path, path)\n","    if os.path.isdir(full_path):\n","        dataset, _ = build_dataset(full_path, paths, db=[lung_name], ds=[train_name])\n","        if ds_train is None:\n","            ds_train = dataset\n","        else:\n","            ds_train = ds_train.concatenate(dataset)\n","\n","        dataset, _ = build_dataset(full_path, paths, db=[lung_name], ds=[test_name])\n","        if ds_test is None:\n","            ds_test = dataset\n","        else:\n","            ds_test = ds_test.concatenate(dataset)\n","\n","        dataset, _ = build_dataset(full_path, paths, db=[lung_name], ds=[valid_name])\n","        if ds_valid is None:\n","            ds_valid = dataset\n","        else:\n","            ds_valid = ds_valid.concatenate(dataset)\n","\n","print(ds_train.cardinality().numpy())\n"]},{"cell_type":"markdown","metadata":{"id":"oULvMsKSelbp"},"source":["Model parameters"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":506,"status":"ok","timestamp":1684688181042,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"St2GGM-zelbp"},"outputs":[],"source":["batch_size_cnn = 32\n","batch_size_transformer = 32\n","\n","image_size = 256\n","input_shape = (image_size, image_size, 1)\n","\n","learning_rate = 0.001\n","weight_decay = 0.0001\n","num_epochs = 100\n","\n","label_smoothing = 0.1\n","lam_recon = 10.\n","patience = 5\n","min_delta = 0.005\n","min_delta_fine_tuning = 0.0005\n","\n","# data augmentation\n","scale = 1. / 255.\n","flip = \"horizontal\"\n","rotation_factor = 10. / 360.\n","zoom_height_factor = 0.2\n","zoom_width_factor = 0.2\n","\n","# vit\n","patch_size = 1\n","transformer_layers = 4\n","num_heads = 8\n","projection_dim = 64\n","transformer_units_rate = [2, 1]\n","mlp_head_units = [1024, 256]  # Size of the dense layers of the final classifier\n"]},{"cell_type":"markdown","metadata":{"id":"HpGXjB_lelbq"},"source":["Data augmentation"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684688185029,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"HMe_zlMGelbq"},"outputs":[],"source":["augmentation = keras.Sequential(\n","    [\n","      layers.Rescaling(scale=scale),\n","      layers.RandomFlip(flip),\n","      layers.RandomRotation(rotation_factor),\n","      layers.RandomZoom(height_factor=zoom_height_factor, width_factor=zoom_width_factor),\n","    ],\n","    name='augmentation'\n",")"]},{"cell_type":"markdown","metadata":{"id":"tQeJmFhXelbq"},"source":["cnn encoder"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1684688186847,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"LOHNNFhrelbq"},"outputs":[],"source":["from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dropout\n","\n","encoder = keras.Sequential(\n","    [\n","      layers.Conv2D(128, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n","      layers.MaxPooling2D(pool_size = (2, 2)),\n","      layers.Conv2D(128, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n","      layers.MaxPooling2D(pool_size = (2, 2)),\n","      layers.Conv2D(64, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n","      layers.MaxPooling2D(pool_size = (2, 2)),\n","      layers.Conv2D(64, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n","      layers.MaxPooling2D(pool_size = (2, 2)),\n","      layers.Conv2D(64, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n","      layers.MaxPooling2D(pool_size = (2, 2)),\n","      layers.Flatten(),\n","    ],\n","    name='encoder'\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"aVIjXbtcelbr","executionInfo":{"status":"ok","timestamp":1684688189319,"user_tz":-120,"elapsed":2,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"}}},"outputs":[],"source":["classifier = keras.Sequential(\n","    [\n","      layers.Dense(1024, activation='relu'),\n","      layers.Dense(256, activation='relu'),\n","      layers.Dense(3, activation='softmax'),\n","    ],\n","    name='classifier'\n",")\n"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":499,"status":"ok","timestamp":1684688193342,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"kX_B3Q95elbs"},"outputs":[],"source":["# Sub Model\n","shared_encoder = keras.Sequential(name='shared_encoder')\n","\n","for layer in encoder.layers[:-1]:\n","  shared_encoder.add(layer)\n","\n","# for layer in shared_encoder.layers:\n","#   layer.trainable = False\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5867,"status":"ok","timestamp":1684688201904,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"0qKrJS3yelbt","outputId":"fa304211-d9e6-4906-ad70-06815af2eacd"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," augmentation (Sequential)      (None, 256, 256, 1)  0           ['input_1[0][0]']                \n","                                                                                                  \n"," shared_encoder (Sequential)    (None, 8, 8, 64)     296512      ['augmentation[0][0]']           \n","                                                                                                  \n"," patches (Patches)              (None, None, 64)     0           ['shared_encoder[0][0]']         \n","                                                                                                  \n"," patch_encoder (PatchEncoder)   (None, 64, 64)       8256        ['patches[0][0]']                \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, 64, 64)      128         ['patch_encoder[0][0]']          \n"," alization)                                                                                       \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, 64, 64)      132672      ['layer_normalization[0][0]',    \n"," dAttention)                                                      'layer_normalization[0][0]']    \n","                                                                                                  \n"," add (Add)                      (None, 64, 64)       0           ['multi_head_attention[0][0]',   \n","                                                                  'patch_encoder[0][0]']          \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, 64, 64)      128         ['add[0][0]']                    \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_4 (Dense)                (None, 64, 128)      8320        ['layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout (Dropout)              (None, 64, 128)      0           ['dense_4[0][0]']                \n","                                                                                                  \n"," dense_5 (Dense)                (None, 64, 64)       8256        ['dropout[0][0]']                \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 64, 64)       0           ['dense_5[0][0]']                \n","                                                                                                  \n"," add_1 (Add)                    (None, 64, 64)       0           ['dropout_1[0][0]',              \n","                                                                  'add[0][0]']                    \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, 64, 64)      128         ['add_1[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, 64, 64)      132672      ['layer_normalization_2[0][0]',  \n"," eadAttention)                                                    'layer_normalization_2[0][0]']  \n","                                                                                                  \n"," add_2 (Add)                    (None, 64, 64)       0           ['multi_head_attention_1[0][0]', \n","                                                                  'add_1[0][0]']                  \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, 64, 64)      128         ['add_2[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_6 (Dense)                (None, 64, 128)      8320        ['layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 64, 128)      0           ['dense_6[0][0]']                \n","                                                                                                  \n"," dense_7 (Dense)                (None, 64, 64)       8256        ['dropout_2[0][0]']              \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 64, 64)       0           ['dense_7[0][0]']                \n","                                                                                                  \n"," add_3 (Add)                    (None, 64, 64)       0           ['dropout_3[0][0]',              \n","                                                                  'add_2[0][0]']                  \n","                                                                                                  \n"," layer_normalization_4 (LayerNo  (None, 64, 64)      128         ['add_3[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_2 (MultiH  (None, 64, 64)      132672      ['layer_normalization_4[0][0]',  \n"," eadAttention)                                                    'layer_normalization_4[0][0]']  \n","                                                                                                  \n"," add_4 (Add)                    (None, 64, 64)       0           ['multi_head_attention_2[0][0]', \n","                                                                  'add_3[0][0]']                  \n","                                                                                                  \n"," layer_normalization_5 (LayerNo  (None, 64, 64)      128         ['add_4[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_8 (Dense)                (None, 64, 128)      8320        ['layer_normalization_5[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 64, 128)      0           ['dense_8[0][0]']                \n","                                                                                                  \n"," dense_9 (Dense)                (None, 64, 64)       8256        ['dropout_4[0][0]']              \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 64, 64)       0           ['dense_9[0][0]']                \n","                                                                                                  \n"," add_5 (Add)                    (None, 64, 64)       0           ['dropout_5[0][0]',              \n","                                                                  'add_4[0][0]']                  \n","                                                                                                  \n"," layer_normalization_6 (LayerNo  (None, 64, 64)      128         ['add_5[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_3 (MultiH  (None, 64, 64)      132672      ['layer_normalization_6[0][0]',  \n"," eadAttention)                                                    'layer_normalization_6[0][0]']  \n","                                                                                                  \n"," add_6 (Add)                    (None, 64, 64)       0           ['multi_head_attention_3[0][0]', \n","                                                                  'add_5[0][0]']                  \n","                                                                                                  \n"," layer_normalization_7 (LayerNo  (None, 64, 64)      128         ['add_6[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_10 (Dense)               (None, 64, 128)      8320        ['layer_normalization_7[0][0]']  \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 64, 128)      0           ['dense_10[0][0]']               \n","                                                                                                  \n"," dense_11 (Dense)               (None, 64, 64)       8256        ['dropout_6[0][0]']              \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 64, 64)       0           ['dense_11[0][0]']               \n","                                                                                                  \n"," add_7 (Add)                    (None, 64, 64)       0           ['dropout_7[0][0]',              \n","                                                                  'add_6[0][0]']                  \n","                                                                                                  \n"," layer_normalization_8 (LayerNo  (None, 64, 64)      128         ['add_7[0][0]']                  \n"," rmalization)                                                                                     \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 4096)         0           ['layer_normalization_8[0][0]']  \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, 4096)         0           ['flatten_1[0][0]']              \n","                                                                                                  \n"," dense_12 (Dense)               (None, 1024)         4195328     ['dropout_8[0][0]']              \n","                                                                                                  \n"," dropout_9 (Dropout)            (None, 1024)         0           ['dense_12[0][0]']               \n","                                                                                                  \n"," dense_13 (Dense)               (None, 256)          262400      ['dropout_9[0][0]']              \n","                                                                                                  \n"," dropout_10 (Dropout)           (None, 256)          0           ['dense_13[0][0]']               \n","                                                                                                  \n"," dense_14 (Dense)               (None, 3)            771         ['dropout_10[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 5,361,411\n","Trainable params: 5,361,411\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["\n","%aimport myLayers.vision_transformer\n","%aimport myLayers.mlp\n","from myLayers.vision_transformer import add_vit\n","\n","inputs = layers.Input(shape=input_shape)\n","augmented_transformer = augmentation(inputs)\n","shared_encoded = shared_encoder(augmented_transformer)\n","features = add_vit(shared_encoded,\n","            patch_size=patch_size,\n","            input_image_size=shared_encoded.shape[1],\n","            transformer_layers=transformer_layers,\n","            num_heads=num_heads,\n","            projection_dim=projection_dim,\n","            transformer_units_rate=transformer_units_rate,\n","            mlp_head_units=mlp_head_units)\n","# Classify outputs.\n","softmax = layers.Dense(3, activation='softmax', kernel_initializer='random_normal')(features)\n","\n","# Create the Keras model\n","model = keras.Model(inputs=inputs, outputs=softmax)\n","# shared_encoder.summary()\n","model.summary()\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"A8WB5ot8MtW5","executionInfo":{"status":"ok","timestamp":1684691549814,"user_tz":-120,"elapsed":981,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"}}},"outputs":[],"source":["# model_name = 'mlops_cnn_vit_model_weights.hdf5'\n","model_name = 'mlops_cnn_vit_model_origin_weights.hdf5'\n","model_full_path = os.path.join(model_path, model_name)\n","model.load_weights(model_full_path)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1818917,"status":"ok","timestamp":1684693463112,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"UdbqZ5jGelbt","outputId":"6b09a24a-fc68-49ff-d8a4-2cb23019eb81"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n","WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"]},{"output_type":"stream","name":"stdout","text":["679/679 [==============================] - ETA: 0s - loss: 0.4898 - accuracy: 0.8918\n","Epoch 1: val_accuracy improved from -inf to 0.91784, saving model to ../output/learning/ckpt/new_model_weights.hdf5\n","679/679 [==============================] - 285s 375ms/step - loss: 0.4898 - accuracy: 0.8918 - val_loss: 0.4453 - val_accuracy: 0.9178\n","Epoch 2/100\n","679/679 [==============================] - ETA: 0s - loss: 0.4902 - accuracy: 0.8916\n","Epoch 2: val_accuracy did not improve from 0.91784\n","679/679 [==============================] - 275s 376ms/step - loss: 0.4902 - accuracy: 0.8916 - val_loss: 0.4762 - val_accuracy: 0.8994\n","Epoch 3/100\n","679/679 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.8902\n","Epoch 3: val_accuracy did not improve from 0.91784\n","679/679 [==============================] - 279s 379ms/step - loss: 0.4928 - accuracy: 0.8902 - val_loss: 0.4689 - val_accuracy: 0.8935\n","Epoch 4/100\n","679/679 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.8914\n","Epoch 4: val_accuracy did not improve from 0.91784\n","679/679 [==============================] - 278s 378ms/step - loss: 0.4892 - accuracy: 0.8914 - val_loss: 0.4503 - val_accuracy: 0.9093\n","Epoch 5/100\n","679/679 [==============================] - ETA: 0s - loss: 0.4905 - accuracy: 0.8917\n","Epoch 5: val_accuracy did not improve from 0.91784\n","679/679 [==============================] - 280s 376ms/step - loss: 0.4905 - accuracy: 0.8917 - val_loss: 0.4528 - val_accuracy: 0.9134\n","Epoch 6/100\n","679/679 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.8922\n","Epoch 6: val_accuracy did not improve from 0.91784\n","679/679 [==============================] - 287s 392ms/step - loss: 0.4920 - accuracy: 0.8922 - val_loss: 0.5200 - val_accuracy: 0.8700\n"]}],"source":["%aimport run_exp.standard\n","from run_exp.standard import run_experiment as run_experiment_transformer\n","\n","model_name = 'new_model'\n","transformer_history = run_experiment_transformer(\n","    model,\n","    ds_train, ds_valid, ds_test,\n","    batch_size=batch_size_transformer, num_epochs=num_epochs,\n","    learning_rate=learning_rate / 2., weight_decay=weight_decay,\n","    from_logits=False, label_smoothing=label_smoothing,\n","    patience=patience, min_delta=min_delta,\n","    log_path=log_path, ckpt_path=ckpt_path,\n","    prefix=model_name\n",")\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"crV7qWT834Vd","executionInfo":{"status":"ok","timestamp":1684691310676,"user_tz":-120,"elapsed":4736,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"}}},"outputs":[],"source":["# model_name = 'new_model'\n","checkpoint_filename = os.path.join(ckpt_path, model_name + '_weights.hdf5')\n","model.load_weights(checkpoint_filename)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70731,"status":"ok","timestamp":1684691391167,"user":{"displayName":"Luc Thomas","userId":"17860019511086541433"},"user_tz":-120},"id":"R1boKCYXEJQs","outputId":"27b94510-63fc-424d-db33-df9d4f285923"},"outputs":[{"output_type":"stream","name":"stdout","text":["172/172 [==============================] - 16s 77ms/step\n","Test accuracy: 92.73%\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.91      0.91      1740\n","           1       0.97      0.94      0.95      1949\n","           2       0.89      0.94      0.91      1803\n","\n","    accuracy                           0.93      5492\n","   macro avg       0.93      0.93      0.93      5492\n","weighted avg       0.93      0.93      0.93      5492\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["['../output/learning/metric/new_model_conf_mat.joblib']"]},"metadata":{},"execution_count":23}],"source":["y_test_pd, y_pred_pd, accuracy, conf_mat, report = compile_test_model(\n","    model,\n","    ds_test, batch_size_transformer,\n","    from_logits=False, label_smoothing=label_smoothing\n",")\n","\n","print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","\n","print(report)\n","f_name = os.path.join(metric_path, model_name + '_report.txt')\n","with open(f_name, \"w\") as text_file:\n","  text_file.write(report)\n","\n","conf_mat\n","f_name = os.path.join(metric_path, model_name + '_conf_mat.joblib')\n","joblib.dump(conf_mat, f_name)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"covid-19-xRay-gI8RPtYc","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ec449b28ee1275c8ed3472cdab9bc054b62d41bc2731e9c066fdcbfc125fb022"}}},"nbformat":4,"nbformat_minor":0}